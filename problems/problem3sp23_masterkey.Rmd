---
title: "Problem Section 3"
subtitle:  "Two sample inference for means"
graphics: yes
output: pdf_document
header-includes: 
- \usepackage{amssymb, amsmath, amsfonts}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=F,warning=F)
library(tidyverse)
library(infer)
```



### Exercises 


1. A group of college students interested in the
effect of stepping exercises on the heart conducted an experiment in which subjects
were randomly assigned to a stepping exercise on either a low step (coded "low") or a high step (coded "high"). Each subject started with a resting heart rate and performed the exercise for 3 minutes, at which time his or her exercise heart rate was measured.
The data are in the file `exercise.csv`. 

a. The students first want to see if the random assignment of subjects
to the groups did a satisfactory job of equalizing the mean resting heart rates between the groups. Explain how to use a confidence interval to look for evidence of a problem with the random assignment. Then go ahead and implement it.

We can construct a 95% CI for the difference between the two means using a t-interval. If we see that the 95% CI contains 0, then that means if we were to do a hypothesis test on whether the two groups (low or high) had different resting heart rates we could fail to reject the null that there is no difference. This would mean that the randomization was done satisfactorily, since there is not enough evidence to reject the hypothesis that each of the two groups has the same mean resting heart rate.

We have this interval as:

```{r}
exercise <- read_csv("exercise.csv") %>% 
  rename(Resting_HR = `Resting HR`,
         Exercise_HR = `Exercise HR`)

#see page 291 of Chap 3 for further reference on t_test
exercise %>% infer::t_test(formula =  Resting_HR ~ Step,
                           order = c("low", "high"))
```

We see the interval contains zero, so we can be 95% confident that the randomization was satisfactory.

b. Next, you want to test whether there is a difference in heart rates between the two groups. Explain how to use a confidence interval to examine this question. Then go ahead and implement it.

We can do a similar process as above but we will have a difference in heart rate for low step, and difference for the high step. We can then do a difference in means t-test, and see if the interval contains zero. If the interval contains zero we would fail to reject the null that higher step leads to a different change in heart rate than lower step. 

```{r}
exercise <- exercise %>% mutate(diff = Exercise_HR - Resting_HR)
exercise %>% t_test(response=diff, 
                    explanatory = Step, 
                    order = c("low","high"))
```


We see that this 95% interval contains zero, so as before, we would fail to reject the null hypothesis that the higher step leads to a different change in heart rate than the lower step.

2. For comparing two means using the t-test, we need to assume the data are normally distributed. With small $n$, it is difficult to judge the shape of a population distribution. Also, if the distribution is skewed the mean is less relevant, but we may still want to test the hypothesis that the two groups have the same distribution. A \emph{permutation test} is a non-parametric method for testing the null hypothesis that the population distributions are identical without specifying their shape.

Consider the following data to determine whether dogs prefer vocal praise or petting. The response variable is the time, in seconds, the animal spent interacting with its owner.

```{r }
dogs <- tibble( 
  group = rep(c("pet","praise"), times = c(7,7)),
  times = c(114, 203, 217,254, 256, 284, 296, 4,7, 24, 25, 48, 71, 294)
  )
```

a. Make a violin plot to compare the distributions. 

```{r}
ggplot(data = dogs, aes(x = group, y=times, fill=group))+geom_violin()+
   labs(x = "Group",
        y = "Time spent Interacting (Sec)",
        title = "Time spent Interacting with Owner vs Type of Interaction")
```

From this we clearly see that the distributions are quite different. 

b. As the true distributions are potentially highly skewed, we focus on the medians. Calculate the observed difference in the medians (pet - praise). This is the observed value of our test statistic. Save it in a variable called `obs_diff_in_median`.

```{r}
obs_diff_in_median <- dogs %>% 
   group_by(group) %>% 
   summarize(med = median(times)) %>% 
   #will create a tibble with a single number
   summarize(obs_diff_in_median = -diff(med)) %>% 
   #pull will extract a number from a tibble
   pull()
obs_diff_in_median
```

c. We test the null hypothesis of identical population distributions against the alternative that the population median is higher for petting using a \textbf{permutation test}. The key to permutation testing is this: 

\emph{if $H_0$ is true, meaning the population distributions are the same, then if we pool all the data and "reshuffle" the pooled values into two new groups of size $n=7$ and $m=7$, we will be sampling from the same (null) distribution. }


The following code implements this method once. We set a seed any time random number generation is involved. After dividing the pooled data into two new groups, we re-calculate the difference in the medians.

```{r label="shuffle-data"}
set.seed(1414)


#sample 7 row numbers
i <- sample(1:nrow(dogs), size = 7, replace=FALSE)    


new_sample1 <- dogs[i,]$times
new_sample2 <- dogs[-i,]$times

median(new_sample1)-median(new_sample2)
  
                                
```

d. We can generate the sampling distribution of the test statistic by generating \emph{all} possible ways to form the two samples of size $n$ and $m$ from the pooled data,  and compute the difference in median for each. Alternately, we could select a subset of the samples randomly and calculate the difference in medians for those. This is the approach we will take here.

The P-value is for the permutation test is the fraction of times the difference between the sample medians is at least `obs_diff_median`.  


Write code to create B=10,000 new "reshuffles" of the pooled data. For each reshuffle, calculate the difference in sample medians. Then make a plot to visualize the null sampling distribution of this statistic. Finally, calculate the  P-value for the permutation test.

```{r}
set.seed(24)
B<-10000

null_sim <- function(x){
   #sample 7 row numbers
   i <- sample(1:nrow(dogs), size = 7, replace=FALSE)    
   
   #dogs[i,] picks the 7 rows sampled above
   new_sample1 <- dogs[i,]$times
   #dogs[-i,] picks everything but the 7 numbers in i
   new_sample2 <- dogs[-i,]$times
   
   diff_median = median(new_sample1)-median(new_sample2)
   return(data.frame(diff_median))
}

null_sim_df <- do.call(rbind,lapply(1:B,null_sim))

ggplot(data = null_sim_df)+
  geom_histogram(aes(x = diff_median, 
                     y = ..density..))+
   geom_vline(xintercept = obs_diff_in_median, col='red')+
  labs(title = "Null Sampling Distribution of Difference in Medians")

```

We have in this case our p-value will be the probability of seeing our observed difference in medians (229), or more extreme according to the above null sampling distribution. Since we notice the null distribution is symmetric, we can simply report our p-value as 2 times the proportion of values greater than 229 in our sampling distribution. Doing this in R we see we have an empirical p-value as:

```{r}
2*mean(null_sim_df$diff_median>=obs_diff_in_median)
```